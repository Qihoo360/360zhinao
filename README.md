<p align="left">
    ä¸­æ–‡</a>&nbsp ï½œ &nbsp<a href="README_EN.md">English</a>&nbsp
</p>
<br>

<div align="center">
<h1>
  360æ™ºè„‘
</h1>
</div>
<div align="center">
    ğŸ¤— <a href="https://huggingface.co/qihoo360">Hugging Face</a>&nbsp&nbsp | &nbsp&nbsp
    ğŸ¤– <a href="https://www.modelscope.cn/profile/qihoo360">ModelScope</a>&nbsp&nbsp ï½œ &nbsp&nbsp
    ğŸ’¬ <a href="./assets/WeChat.png">WeChat (å¾®ä¿¡)</a>&nbsp&nbsp
</div>
<br>
<p align="center">
 æ¬¢è¿è®¿é—®360æ™ºè„‘å®˜ç½‘<a href="https://ai.360.com"> https://ai.360.com </a>ä½“éªŒæ›´å¤šæ›´å¼ºå¤§çš„åŠŸèƒ½ã€‚
</p>

<br>

# æ¨¡å‹ä»‹ç»
 ğŸ‰ğŸ‰ğŸ‰æˆ‘ä»¬å¼€æºäº†360æ™ºè„‘å¤§æ¨¡å‹çš„ç³»åˆ—å·¥ä½œï¼Œæœ¬æ¬¡å¼€æºäº†ä»¥ä¸‹æ¨¡å‹ï¼š
 - **360Zhinao-7B-Base**
 - **360Zhinao-7B-Chat-4K**
 - **360Zhinao-7B-Chat-32K**
 - **360Zhinao-7B-Chat-360K**

360æ™ºè„‘å¤§æ¨¡å‹ç‰¹ç‚¹å¦‚ä¸‹ï¼š
- **åŸºç¡€æ¨¡å‹**ï¼šé‡‡ç”¨ 3.4 ä¸‡äº¿ Tokens çš„é«˜è´¨é‡è¯­æ–™åº“è®­ç»ƒï¼Œä»¥ä¸­æ–‡ã€è‹±æ–‡ã€ä»£ç ä¸ºä¸»ï¼Œåœ¨ç›¸å…³åŸºå‡†è¯„æµ‹ä¸­ï¼ŒåŒå°ºå¯¸æœ‰ç«äº‰åŠ›ã€‚
- **å¯¹è¯æ¨¡å‹**ï¼šå…·æœ‰å¼ºå¤§çš„å¯¹è¯èƒ½åŠ›ï¼Œå¼€æ”¾4Kã€32Kã€360Kä¸‰ç§ä¸åŒæ–‡æœ¬é•¿åº¦ã€‚æ®äº†è§£ï¼Œ360Kï¼ˆçº¦50ä¸‡å­—ï¼‰æ˜¯å½“å‰å›½äº§å¼€æºæ¨¡å‹æ–‡æœ¬é•¿åº¦æœ€é•¿çš„ã€‚

<br>

# æ›´æ–°ä¿¡æ¯
- [2024.04.10] æˆ‘ä»¬å‘å¸ƒäº†360Zhinao-7B 1.0ç‰ˆæœ¬ï¼ŒåŒæ—¶å¼€æ”¾Baseæ¨¡å‹å’Œ4Kã€32Kã€360Kä¸‰ç§æ–‡æœ¬é•¿åº¦çš„Chatæ¨¡å‹ã€‚

<br>

# ç›®å½•
- [ä¸‹è½½åœ°å€](#ä¸‹è½½åœ°å€)
- [æ¨¡å‹è¯„ä¼°](#æ¨¡å‹è¯„ä¼°)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [æ¨¡å‹æ¨ç†](#æ¨¡å‹æ¨ç†)
- [æ¨¡å‹å¾®è°ƒ](#æ¨¡å‹å¾®è°ƒ)
- [è®¸å¯è¯](#è®¸å¯è¯)

<br>

# ä¸‹è½½åœ°å€
æœ¬æ¬¡å‘å¸ƒç‰ˆæœ¬å’Œä¸‹è½½é“¾æ¥è§ä¸‹è¡¨ï¼š
| Size | Model | BF16 | Int4|
|:-:|-|:-:|:-:|
| 7B | 360Zhinao-7B-Base | <a href="https://www.modelscope.cn/models/qihoo360/360Zhinao-7B-Base/summary">ğŸ¤–</a>  <a href="https://huggingface.co/qihoo360/360Zhinao-7B-Base">ğŸ¤—</a> |  |
| 7B | 360Zhinao-7B-Chat-4K | <a href="https://www.modelscope.cn/models/qihoo360/360Zhinao-7B-Chat-4K/summary">ğŸ¤–</a>  <a href="https://huggingface.co/qihoo360/360Zhinao-7B-Chat-4K">ğŸ¤—</a> | <a href="https://www.modelscope.cn/models/qihoo360/360Zhinao-7B-Chat-4K-Int4/summary">ğŸ¤–</a>  <a href="https://huggingface.co/qihoo360/360Zhinao-7B-Chat-4K-Int4">ğŸ¤—</a> |
| 7B | 360Zhinao-7B-Chat-32K | <a href="https://www.modelscope.cn/models/qihoo360/360Zhinao-7B-Chat-32K/summary">ğŸ¤–</a>  <a href="https://huggingface.co/qihoo360/360Zhinao-7B-Chat-32K">ğŸ¤—</a> | <a href="https://www.modelscope.cn/models/qihoo360/360Zhinao-7B-Chat-32K-Int4/summary">ğŸ¤–</a>  <a href="https://huggingface.co/qihoo360/360Zhinao-7B-Chat-32K-Int4">ğŸ¤—</a> |
| 7B | 360Zhinao-7B-Chat-360K | <a href="https://www.modelscope.cn/models/qihoo360/360Zhinao-7B-Chat-360K/summary">ğŸ¤–</a>  <a href="https://huggingface.co/qihoo360/360Zhinao-7B-Chat-360K">ğŸ¤—</a> | <a href="https://www.modelscope.cn/models/qihoo360/360Zhinao-7B-Chat-360K-Int4/summary">ğŸ¤–</a>  <a href="https://huggingface.co/qihoo360/360Zhinao-7B-Chat-360K-Int4">ğŸ¤—</a> |

<br>

# æ¨¡å‹è¯„ä¼°

## åŸºç¡€æ¨¡å‹
æˆ‘ä»¬åœ¨OpenCompassçš„ä¸»æµè¯„æµ‹æ•°æ®é›†ä¸ŠéªŒè¯äº†æˆ‘ä»¬çš„æ¨¡å‹æ€§èƒ½ï¼ŒåŒ…æ‹¬C-Evalã€AGIEvalã€MMLUã€CMMLUã€HellaSwagã€MATHã€GSM8Kã€HumanEvalã€MBPPã€BBHã€LAMBADAï¼Œè€ƒå¯Ÿçš„èƒ½åŠ›åŒ…æ‹¬è‡ªç„¶è¯­è¨€ç†è§£ã€çŸ¥è¯†ã€æ•°å­¦è®¡ç®—å’Œæ¨ç†ã€ä»£ç ç”Ÿæˆã€é€»è¾‘æ¨ç†ç­‰ã€‚


| <div style="width: 100pt">Model</div> | AVG   | CEval | AGIEval | MMLU | CMMLU | HellaSwag | MATH | GSM8K | HumanEval | MBPP | BBH | LAMBADA |
|:----------------------|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|:---------:|
| Baichuan2-7B          | 41.49     | 56.3      | 34.6      | 54.7      | 57        | 67        | 5.4       | 24.6      | 17.7      | 24        | 41.8      | 73.3      |
| Baichuan-7B           | 31.94     | 44.7      | 24.6      | 41.5      | 44.6      | 68.4      | 2.5       | 9.6       | 9.1       | 6.4       | 32.8      | 67.1      |
| ChatGLM3-6B           | **58.67** | 67        | 47.4      | 62.8      | 66.5      | 76.5      | 19.2      | 61        | 44.5      | **57.2**  | **66.2**  | 77.1      |
| DeepSeek-7B           | 39.8      | 45        | 24        | 49.3      | 46.8      | 73.4      | 4.2       | 18.3      | 25        | 36.4      | 42.8      | 72.6      |
| InternLM2-7B          | 58.01     | 65.7      | 50.2      | 65.5      | 66.2      | 79.6      | 19.9      | **70.6**  | 41.5      | 42.4      | 64.4      | 72.1      |
| InternLM-7B           | 39.33     | 53.4      | 36.9      | 51        | 51.8      | 70.6      | 6.3       | 31.2      | 13.4      | 14        | 37        | 67        |
| LLaMA-2-7B            | 33.27     | 32.5      | 21.8      | 46.8      | 31.8      | 74        | 3.3       | 16.7      | 12.8      | 14.8      | 38.2      | 73.3      |
| LLaMA-7B              | 30.35     | 27.3      | 20.6      | 35.6      | 26.8      | 74.3      | 2.9       | 10        | 12.8      | 16.8      | 33.5      | 73.3      |
| Mistral-7B-v0.1       | 47.67     | 47.4      | 32.8      | 64.1      | 44.7      | 78.9      | 11.3      | 47.5      | 27.4      | 38.6      | 56.7      | 75        |
| MPT-7B                | 30.06     | 23.5      | 21.3      | 27.5      | 25.9      | 75        | 2.9       | 9.1       | 17.1      | 22.8      | 35.6      | 70        |
| Qwen1.5-7B            | 55.12     | 73.57     | **50.8**  | 62.15     | 71.84     | 72.62     | **20.36** | 54.36     | **53.05** | 36.8      | 40.01     | 70.74     |
| Qwen-7B               | 49.53     | 63.4      | 45.3      | 59.7      | 62.5      | 75        | 13.3      | 54.1      | 27.4      | 31.4      | 45.2      | 67.5      |
| XVERSE-7B             | 34.27     | 61.1      | 39        | 58.4      | 60.8      | 73.7      | 2.2       | 11.7      | 4.9       | 10.2      | 31        | 24        |
| Yi-6B                 | 47.8      | 73        | 44.3      | 64        | **73.5**  | 73.1      | 6.3       | 39.9      | 15.2      | 23.6      | 44.9      | 68        |
| **360Zhinao-7B**      | 56.15     | **74.11** | 49.49     | **67.44** | 72.38     | **83.05** | 16.38     | 53.83     | 35.98     | 42.4      | 43.95     | **78.59** |

ä»¥ä¸Šç»“æœï¼Œåœ¨å®˜æ–¹[Opencompass](https://rank.opencompass.org.cn/leaderboard-llm)ä¸Šå¯æŸ¥è¯¢æˆ–å¯å¤ç°ã€‚

## Chatæ¨¡å‹

  æˆ‘ä»¬é‡‡ç”¨ä¸¤é˜¶æ®µçš„æ–¹å¼è®­ç»ƒé•¿æ–‡æœ¬æ¨¡å‹.
  
  **ç¬¬ä¸€é˜¶æ®µ**ï¼šæˆ‘ä»¬å¢å¤§RoPE baseï¼Œå°†ä¸Šä¸‹æ–‡é•¿åº¦æ‰©å±•è‡³32Kè®­ç»ƒï¼š
    - é¦–å…ˆï¼Œå¯¹åŸºç¡€æ¨¡å‹è¿›è¡Œäº†çº¦5B tokensçš„32Kçª—å£ç»§ç»­é¢„è®­ç»ƒã€‚
    - æ¥ç€ï¼ŒSFTé˜¶æ®µä½¿ç”¨äº†å¤šç§å½¢å¼å’Œæ¥æºçš„é•¿æ–‡æœ¬æ•°æ®ï¼ŒåŒ…æ‹¬é«˜è´¨é‡çš„äººå·¥æ ‡æ³¨32Ké•¿æ–‡æœ¬æ•°æ®ã€‚

  **ç¬¬äºŒé˜¶æ®µ**ï¼šæˆ‘ä»¬å°†ä¸Šä¸‹æ–‡é•¿åº¦æ‰©å±•è‡³360Kè¿›è¡Œè®­ç»ƒï¼Œä½¿ç”¨æ•°æ®å¦‚ä¸‹ï¼š
    - å°‘é‡é«˜è´¨é‡äººå·¥æ ‡æ³¨æ•°æ®ã€‚
    - ç”±äºå¸¦æœ‰æ ‡æ³¨çš„è¶…é•¿æ–‡æœ¬æ•°æ®çš„ç¨€ç¼ºæ€§ï¼Œæˆ‘ä»¬æ„é€ äº†å¤šç§å½¢å¼çš„åˆæˆæ•°æ®ï¼š
      - å¤šæ–‡æ¡£é—®ç­”ï¼šç±»ä¼¼[Ziya-Reader](https://arxiv.org/abs/2311.09198)ï¼Œæˆ‘ä»¬åŸºäº360è‡ªæœ‰æ•°æ®æ„é€ äº†å¤šç§ç±»å‹çš„å¤šæ–‡æ¡£é—®ç­”æ•°æ®ï¼ŒåŒæ—¶å°†é—®ç­”æ”¹ä¸ºå¤šè½®ï¼Œæ˜¾è‘—æå‡é•¿æ–‡æœ¬çš„è®­ç»ƒæ•ˆç‡ã€‚
      - å•æ–‡æ¡£é—®ç­”ï¼šç±»ä¼¼[LLama2 Long](https://arxiv.org/abs/2309.16039)ï¼Œæˆ‘ä»¬æ„é€ äº†åŸºäºè¶…é•¿æ–‡æœ¬å„ä¸ªç‰‡æ®µçš„å¤šè½®é—®ç­”æ•°æ®ã€‚

æˆ‘ä»¬åœ¨å¤šç§é•¿åº¦å’Œå¤šç§ä»»åŠ¡çš„è¯„æµ‹Benchmarkä¸ŠéªŒè¯ä¸åŒç‰ˆæœ¬æ¨¡å‹çš„æ€§èƒ½ã€‚

- ### 360Zhinao-7B-Chat-32Kæ¨¡å‹é•¿æ–‡æœ¬èƒ½åŠ›è¯„æµ‹


  æˆ‘ä»¬ä½¿ç”¨LongBenchéªŒè¯é•¿æ–‡æœ¬æ•ˆæœã€‚[LongBench](https://github.com/THUDM/LongBench)æ˜¯ç¬¬ä¸€ä¸ªå¤šä»»åŠ¡ã€ä¸­è‹±åŒè¯­ã€é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹é•¿æ–‡æœ¬ç†è§£èƒ½åŠ›çš„è¯„æµ‹åŸºå‡†ã€‚LongBenchç”±å…­å¤§ç±»ã€äºŒåä¸€ä¸ªä¸åŒçš„ä»»åŠ¡ç»„æˆï¼Œæˆ‘ä»¬é€‰æ‹©å…¶ä¸­ä¸ä¸­æ–‡é•¿æ–‡æœ¬åº”ç”¨æœ€å¯†åˆ‡ç›¸å…³çš„ä¸­æ–‡å•æ–‡æ¡£é—®ç­”ã€å¤šæ–‡æ¡£é—®ç­”ã€æ‘˜è¦ã€Few-shotç­‰ä»»åŠ¡è¿›è¡Œè¯„æµ‹ã€‚

    | Model                     | Avg       | å•æ–‡æ¡£QA  | å¤šæ–‡æ¡£QA   | æ‘˜è¦       | Few-shotå­¦ä¹  | ä»£ç è¡¥å…¨    |
    | :------------------------ |:---------:|:--------:|:---------:|:---------:|:------------:|:---------:|
    | GPT-3.5-Turbo-16k         | 37.84     | 61.2     | 28.7      | 16        | 29.2         | 54.1      |
    | ChatGLM2-6B-32k           | 37.16     | 51.6     | 37.6      | 16.2      | 27.7         | 52.7      |
    | ChatGLM3-6B-32k           | 44.62     | **62.3** | 44.8      | 17.8      | 42           | 56.2      |
    | InternLM2-Chat-7B         | 42.20     | 56.65    | 29.15     | **17.99** | 43.5         | **63.72** |
    | Qwen1.5-Chat-7B           | 36.75     | 52.85    | 30.08     | 14.28     | 32           | 54.55     |
    | Qwen1.5-Chat-14B          | 39.80     | 60.39    | 27.99     | 14.77     | 37           | 58.87     |
    | 360Zhinao-7B-Chat-32K     | **45.18** | 57.18    | **48.06** | 15.03     | **44**       | 61.64     |

- ### 360Zhinao-7B-Chat-360Kâ€œå¤§æµ·æé’ˆâ€æµ‹è¯•

  å¤§æµ·æé’ˆæµ‹è¯•ï¼ˆ[NeedleInAHaystack](https://github.com/gkamradt/LLMTest_NeedleInAHaystack)ï¼‰æ˜¯å°†å…³é”®ä¿¡æ¯æ’å…¥ä¸€æ®µé•¿æ–‡æœ¬çš„ä¸åŒä½ç½®ï¼Œå†å¯¹è¯¥å…³é”®ä¿¡æ¯æé—®ï¼Œä»è€Œæµ‹è¯•å¤§æ¨¡å‹çš„é•¿æ–‡æœ¬èƒ½åŠ›çš„ä¸€ç§æ–¹æ³•ã€‚

  360Zhinao-7B-Chat-360Kåœ¨ä¸­è‹±æ–‡å¤§æµ·æé’ˆä¸­éƒ½èƒ½è¾¾åˆ°98%ä»¥ä¸Šçš„å‡†ç¡®ç‡ã€‚

  - è‹±æ–‡"å¤§æµ·æé’ˆ"ï¼ˆå’Œ[NeedleInAHaystack](https://github.com/gkamradt/LLMTest_NeedleInAHaystack)ç›¸åŒï¼‰
  
    <p align="center">
        <img src="assets/360Zhinao-7B-Chat-360K.en_score.png" width="600" />
    <p>

    **é’ˆ**ï¼šThe best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.

    **æé—®**ï¼šWhat is the best thing to do in San Francisco?


  - ä¸­æ–‡â€œå¤§æµ·æé’ˆâ€

    <p align="center">
        <img src="assets/360Zhinao-7B-Chat-360K.zh_score.png" width="600" />
    <p>

    æˆ‘ä»¬ä»¿ç…§[SuperCLUE-200Kæµ‹è¯„åŸºå‡†](https://mp.weixin.qq.com/s/QgoRf2LB-7vc3vTFOHJkpw)æ„é€ äº†ä¸­æ–‡å¤§æµ·æé’ˆï¼š

    **æµ·**ï¼šé•¿ç¯‡å°è¯´ã€‚
    
    **é’ˆ**ï¼šç‹è½æ˜¯ä¸€åå‹¤å¥‹çš„åº—å‘˜ï¼Œä»–æ¯å¤©å‡Œæ™¨å°±èµ·åºŠï¼Œèµ¶åœ¨ç¬¬ä¸€ç¼•é˜³å…‰ç…§äº®å¤§åœ°ä¹‹å‰åˆ°è¾¾åº—é“ºï¼Œä¸ºå³å°†å¼€å§‹çš„ä¸€å¤©åšå‡†å¤‡ã€‚ä»–æ¸…æ‰«åº—é“ºï¼Œæ•´ç†è´§æ¶ï¼Œä¸ºé¡¾å®¢æä¾›æ–¹ä¾¿ã€‚ä»–å¯¹äº”é‡‘çš„ç§ç±»å’Œç”¨é€”äº†å¦‚æŒ‡æŒï¼Œæ— è®ºé¡¾å®¢éœ€è¦ä»€ä¹ˆï¼Œä»–æ€»èƒ½å‡†ç¡®åœ°æ‰¾åˆ°ã€‚\nç„¶è€Œï¼Œä»–çš„è€æ¿åˆ˜ç§€å´æ€»æ˜¯å¯¹ä»–å¹æ¯›æ±‚ç–µã€‚åˆ˜ç§€æ˜¯ä¸ªæŒ‘å‰”çš„äººï¼Œä»–æ€»èƒ½åœ¨ç‹è½çš„å·¥ä½œä¸­æ‰¾å‡ºä¸€äº›å°é”™è¯¯ï¼Œç„¶åä»¥æ­¤ä¸ºç”±æ‰£ä»–çš„å·¥èµ„ã€‚ä»–å¯¹ç‹è½çš„å·¥ä½œè¦æ±‚éå¸¸ä¸¥æ ¼ï¼Œç”šè‡³æœ‰äº›è¿‡åˆ†ã€‚å³ä½¿ç‹è½åšå¾—å†å¥½ï¼Œåˆ˜ç§€ä¹Ÿæ€»èƒ½æ‰¾å‡ºä¸€äº›å°é—®é¢˜ï¼Œè®©ç‹è½æ„Ÿåˆ°éå¸¸æ²®ä¸§ã€‚\nç‹è½è™½ç„¶å¯¹æ­¤æ„Ÿåˆ°ä¸æ»¡ï¼Œä½†ä»–å¹¶æ²¡æœ‰æ”¾å¼ƒã€‚ä»–çŸ¥é“ï¼Œåªæœ‰é€šè¿‡è‡ªå·±çš„åŠªåŠ›ï¼Œæ‰èƒ½è·å¾—æ›´å¥½çš„ç”Ÿæ´»ã€‚ä»–åšæŒæ¯å¤©æ—©èµ·ï¼Œå°½ç®¡ä»–çŸ¥é“é‚£å¤©å¯èƒ½ä¼šå†æ¬¡è¢«åˆ˜ç§€æ‰£å·¥èµ„ã€‚ä»–å§‹ç»ˆä¿æŒå¾®ç¬‘ï¼Œå°½ç®¡ä»–çŸ¥é“åˆ˜ç§€å¯èƒ½ä¼šå†æ¬¡å¯¹ä»–æŒ‘å‰”ã€‚

    **æé—®**ï¼šç‹è½åœ¨è°çš„æ‰‹ä¸‹å·¥ä½œï¼Ÿ

<br>

# å¿«é€Ÿå¼€å§‹
ç®€å•çš„ç¤ºä¾‹æ¥è¯´æ˜å¦‚ä½•åˆ©ç”¨ğŸ¤– ModelScopeå’ŒğŸ¤— Transformerså¿«é€Ÿä½¿ç”¨360Zhinao-7B-Baseå’Œ360Zhinao-7B-Chat

## ä¾èµ–å®‰è£…
- python 3.8 and above
- pytorch 2.0 and above
- transformers 4.37.2 and above
- CUDA 11.4 and above are recommended.

```shell
pip install -r requirements.txt 
```
æˆ‘ä»¬æ¨èå®‰è£…flash-attentionï¼ˆå½“å‰å·²æ”¯æŒflash attention 2ï¼‰æ¥æé«˜ä½ çš„è¿è¡Œæ•ˆç‡ä»¥åŠé™ä½æ˜¾å­˜å ç”¨ã€‚(flash-attentionåªæ˜¯å¯é€‰é¡¹ï¼Œä¸å®‰è£…ä¹Ÿå¯æ­£å¸¸è¿è¡Œè¯¥é¡¹ç›®)

>flash-attn >= 2.3.6
```shell
FLASH_ATTENTION_FORCE_BUILD=TRUE pip install flash-attn==2.3.6
```


## ğŸ¤— Transformers
### Baseæ¨¡å‹æ¨ç†

æ­¤ä»£ç æ¼”ç¤ºä½¿ç”¨transformerså¿«é€Ÿä½¿ç”¨360Zhinao-7B-Baseæ¨¡å‹è¿›è¡Œæ¨ç†
```python
from transformers import AutoTokenizer, AutoModelForCausalLM
from transformers.generation import GenerationConfig

MODEL_NAME_OR_PATH = "qihoo360/360Zhinao-7B-Base"

tokenizer = AutoTokenizer.from_pretrained(
    MODEL_NAME_OR_PATH, 
    trust_remote_code=True)

model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME_OR_PATH,
    device_map="auto",
    trust_remote_code=True)

generation_config = GenerationConfig.from_pretrained(
    MODEL_NAME_OR_PATH,
    trust_remote_code=True)

inputs = tokenizer('ä¸­å›½äºŒåå››èŠ‚æ°”\n1. ç«‹æ˜¥\n2. é›¨æ°´\n3. æƒŠè›°\n4. æ˜¥åˆ†\n5. æ¸…æ˜\n', return_tensors='pt')
inputs = inputs.to(model.device)

pred = model.generate(input_ids=inputs["input_ids"], generation_config=generation_config)
print("outputs:\n", tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))
```

### Chatæ¨¡å‹æ¨ç†

æ­¤ä»£ç æ¼”ç¤ºä½¿ç”¨transformerså¿«é€Ÿä½¿ç”¨360Zhinao-7B-Chat-4Kæ¨¡å‹è¿›è¡Œæ¨ç†
```python
from transformers import AutoTokenizer, AutoModelForCausalLM
from transformers.generation import GenerationConfig

MODEL_NAME_OR_PATH = "qihoo360/360Zhinao-7B-Chat-4K"

tokenizer = AutoTokenizer.from_pretrained(
    MODEL_NAME_OR_PATH, 
    trust_remote_code=True)

model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME_OR_PATH,
    device_map="auto",
    trust_remote_code=True)

generation_config = GenerationConfig.from_pretrained(
    MODEL_NAME_OR_PATH,
    trust_remote_code=True)

messages = []
#round-1
messages.append({"role": "user", "content": "ä»‹ç»ä¸€ä¸‹åˆ˜å¾·å"})
response = model.chat(tokenizer=tokenizer, messages=messages, generation_config=generation_config)
messages.append({"role": "assistant", "content": response})
print(messages)

#round-2
messages.append({"role": "user", "content": "ä»–æœ‰ä»€ä¹ˆä»£è¡¨ä½œï¼Ÿ"})
response = model.chat(tokenizer=tokenizer, messages=messages, generation_config=generation_config)
messages.append({"role": "assistant", "content": response})
print(messages)
```

## ğŸ¤– ModelScope
### Baseæ¨¡å‹æ¨ç†

æ­¤ä»£ç æ¼”ç¤ºä½¿ç”¨ModelScopeå¿«é€Ÿä½¿ç”¨360Zhinao-7B-Baseæ¨¡å‹è¿›è¡Œæ¨ç†


```python
from modelscope import AutoModelForCausalLM, AutoTokenizer
from modelscope import GenerationConfig

MODEL_NAME_OR_PATH = "qihoo360/360Zhinao-7B-Base"

tokenizer = AutoTokenizer.from_pretrained(
    MODEL_NAME_OR_PATH, 
    trust_remote_code=True)

model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME_OR_PATH,
    device_map="auto",
    trust_remote_code=True)

generation_config = GenerationConfig.from_pretrained(
    MODEL_NAME_OR_PATH,
    trust_remote_code=True)

inputs = tokenizer('ä¸­å›½äºŒåå››èŠ‚æ°”\n1. ç«‹æ˜¥\n2. é›¨æ°´\n3. æƒŠè›°\n4. æ˜¥åˆ†\n5. æ¸…æ˜\n', return_tensors='pt')
inputs = inputs.to(model.device)

pred = model.generate(input_ids=inputs["input_ids"], generation_config=generation_config)
print("outputs:\n", tokenizer.decode(pred.cpu()[0], skip_special_tokens=True))
```

### Chatæ¨¡å‹æ¨ç†

æ­¤ä»£ç æ¼”ç¤ºä½¿ç”¨ModelScopeå¿«é€Ÿä½¿ç”¨360Zhinao-7B-Chat-4Kæ¨¡å‹è¿›è¡Œæ¨ç†
```python
from modelscope import AutoModelForCausalLM, AutoTokenizer
from modelscope import GenerationConfig

MODEL_NAME_OR_PATH = "qihoo360/360Zhinao-7B-Chat-4K"

tokenizer = AutoTokenizer.from_pretrained(
    MODEL_NAME_OR_PATH, 
    trust_remote_code=True)

model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME_OR_PATH,
    device_map="auto",
    trust_remote_code=True)

generation_config = GenerationConfig.from_pretrained(
    MODEL_NAME_OR_PATH,
    trust_remote_code=True)

messages = []
#round-1
messages.append({"role": "user", "content": "ä»‹ç»ä¸€ä¸‹åˆ˜å¾·å"})
response = model.chat(tokenizer=tokenizer, messages=messages, generation_config=generation_config)
messages.append({"role": "assistant", "content": response})
print(messages)

#round-2
messages.append({"role": "user", "content": "ä»–æœ‰ä»€ä¹ˆä»£è¡¨ä½œï¼Ÿ"})
response = model.chat(tokenizer=tokenizer, messages=messages, generation_config=generation_config)
messages.append({"role": "assistant", "content": response})
print(messages)
```

## ç»ˆç«¯ Demo
å¯ä½¿ç”¨ç»ˆç«¯äº¤äº’å®ç°å¿«é€Ÿä½“éªŒ
```shell
python cli_demo.py
```
<p align="center">
    <img src="assets/cli_demo.gif" width="600" />
<p>

## ç½‘é¡µ Demo
ä¹Ÿå¯ä½¿ç”¨ç½‘é¡µäº¤äº’å®ç°å¿«é€Ÿä½“éªŒ
```shell
streamlit run web_demo.py
```
<p align="center">
    <img src="assets/web_demo.gif" width="600" />
<p>

## API Demo
å¯åŠ¨å‘½ä»¤
```shell
python openai_api.py
```

è¯·æ±‚å‚æ•°
```shell
curl 'http://localhost:8360/v1/chat/completions' \
-H 'Content-Type: application/json' \
-d '{
    "max_new_tokens": 200,
    "do_sample": true,
    "top_k": 0,
    "top_p": 0.8,
    "temperature": 1.0,
    "repetition_penalty": 1.0,
    "messages": [
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "ä½ å¥½"}
    ]
}'
```

<br>

# æ¨¡å‹æ¨ç†
## æ¨¡å‹é‡åŒ–
æˆ‘ä»¬æä¾›äº†åŸºäºAutoGPTQçš„é‡åŒ–æ–¹æ¡ˆï¼Œå¹¶å¼€æºäº†Int4é‡åŒ–æ¨¡å‹ã€‚

## æ¨¡å‹éƒ¨ç½²
### vLLMå®‰è£…ç¯å¢ƒ
å¦‚å¸Œæœ›éƒ¨ç½²åŠåŠ é€Ÿæ¨ç†ï¼Œæˆ‘ä»¬å»ºè®®ä½ ä½¿ç”¨ `vLLM==0.3.3`ã€‚

å¦‚æœä½ ä½¿ç”¨**CUDA 12.1å’ŒPyTorch 2.1**ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…vLLMã€‚
```shell
pip install vllm==0.3.3
```

å¦åˆ™è¯·å‚è€ƒvLLMå®˜æ–¹çš„[å®‰è£…è¯´æ˜](https://docs.vllm.ai/en/latest/getting_started/installation.html)ã€‚

>å®‰è£…å®Œæˆåï¼Œè¿˜éœ€è¦ä»¥ä¸‹æ“ä½œ~
1. æŠŠvllm/zhinao.pyæ–‡ä»¶å¤åˆ¶åˆ°envç¯å¢ƒå¯¹åº”çš„vllm/model_executor/modelsç›®å½•ä¸‹ã€‚
2. æŠŠvllm/serving_chat.pyæ–‡ä»¶å¤åˆ¶åˆ°envç¯å¢ƒå¯¹åº”çš„vllm/entrypoints/openaiç›®å½•ä¸‹ã€‚
3. ç„¶ååœ¨vllm/model_executor/models/\_\_init\_\_.pyæ–‡ä»¶å¢åŠ ä¸€è¡Œä»£ç 

    ```shell
    "ZhinaoForCausalLM": ("zhinao", "ZhinaoForCausalLM"),
    ```

### vLLMæœåŠ¡å¯åŠ¨

å¯åŠ¨æœåŠ¡
```shell
python -m vllm.entrypoints.openai.api_server \
    --served-model-name 360Zhinao-7B-Chat-4K \
    --model qihoo360/360Zhinao-7B-Chat-4K \
    --trust-remote-code \
    --tensor-parallel-size 1 \
    --max-model-len 4096 \
    --host 0.0.0.0 \
    --port 8360
```

ä½¿ç”¨curlè¯·æ±‚æœåŠ¡
```shell
curl http://localhost:8360/v1/chat/completions \
-H "Content-Type: application/json" \
-d '{
    "model": "360Zhinao-7B-Chat-4K",
    "max_tokens": 200,
    "top_k": -1,
    "top_p": 0.8,
    "temperature": 1.0,
    "presence_penalty": 0.0,
    "frequency_penalty": 0.0,
    "messages": [
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "ä½ å¥½"}
    ],
    "stop": [
        "<eod>",
        "<|im_end|>",
        "<|im_start|>"
    ]
}'
```
ä½¿ç”¨pythonè¯·æ±‚æœåŠ¡
```python
from openai import OpenAI
# Set OpenAI's API key and API base to use vLLM's API server.
openai_api_key = "EMPTY"
openai_api_base = "http://localhost:8360/v1"

client = OpenAI(
    api_key=openai_api_key,
    base_url=openai_api_base,
)

chat_response = client.chat.completions.create(
    model="360Zhinao-7B-Chat-4K",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "ä½ å¥½"},
    ],
    stop=[
        "<eod>",
        "<|im_end|>",
        "<|im_start|>"
    ],
    presence_penalty=0.0,
    frequency_penalty=0.0
)
print("Chat response:", chat_response)
```

> æ³¨æ„ï¼šå¦‚éœ€è¦å¼€å¯é‡å¤æƒ©ç½šï¼Œå»ºè®®ä½¿ç”¨ *presence_penalty* å’Œ *frequency_penalty* å‚æ•°ã€‚

<br>

# æ¨¡å‹å¾®è°ƒ
## è®­ç»ƒæ•°æ®

æˆ‘ä»¬æä¾›äº†å¾®è°ƒè®­ç»ƒæ ·ä¾‹æ•°æ® data/test.jsonï¼Œè¯¥æ ·ä¾‹æ•°æ®æ˜¯ä» [multiturn_chat_0.8M](https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M) é‡‡æ ·å‡º 1 ä¸‡æ¡ï¼Œå¹¶ä¸”åšäº†æ ¼å¼è½¬æ¢ã€‚

æ•°æ®æ ¼å¼:
```json
[
  {
    "id": 1,
    "conversations": [
        {
            "from": "system",
            "value": "You are a helpful assistant."
        },
        {
            "from": "user",
            "value": "æ‚¨å¥½å•Š"
        },
        {
            "from": "assistant",
            "value": "ä½ å¥½ï¼æˆ‘ä»Šå¤©èƒ½ä¸ºæ‚¨åšäº›ä»€ä¹ˆï¼Ÿæœ‰ä»€ä¹ˆé—®é¢˜æˆ–éœ€è¦å¸®åŠ©å—? æˆ‘åœ¨è¿™é‡Œä¸ºæ‚¨æä¾›æœåŠ¡ã€‚"
        }
    ]
  }
]
```

## å¾®è°ƒè®­ç»ƒ
è®­ç»ƒè„šæœ¬å¦‚ä¸‹ï¼š
```shell
set -x

HOSTFILE=hostfile
DS_CONFIG=./finetune/ds_config_zero2.json

# PARAMS
LR=5e-6
EPOCHS=3
MAX_LEN=4096
BATCH_SIZE=4
NUM_NODES=1
NUM_GPUS=8
MASTER_PORT=29500

IS_CONCAT=False # æ˜¯å¦æ•°æ®æ‹¼æ¥åˆ°æœ€å¤§é•¿åº¦ï¼ˆMAX_LENï¼‰

DATA_PATH="./data/training_data_sample.json"
MODEL_PATH="qihoo360/360Zhinao-7B-Base"
OUTPUT_DIR="./outputs/"

deepspeed --hostfile ${HOSTFILE} \
        --master_port ${MASTER_PORT} \
        --num_nodes ${NUM_NODES} \
        --num_gpus ${NUM_GPUS} \
        finetune.py \
        --report_to "tensorboard" \
        --data_path ${DATA_PATH} \
        --model_name_or_path ${MODEL_PATH} \
        --output_dir ${OUTPUT_DIR} \
        --model_max_length ${MAX_LEN} \
        --num_train_epochs ${EPOCHS} \
        --per_device_train_batch_size ${BATCH_SIZE} \
        --gradient_accumulation_steps 1 \
        --save_strategy steps \
        --save_steps 200 \
        --learning_rate ${LR} \
        --lr_scheduler_type cosine \
        --adam_beta1 0.9 \
        --adam_beta2 0.95 \
        --adam_epsilon 1e-8 \
        --max_grad_norm 1.0 \
        --weight_decay 0.1 \
        --warmup_ratio 0.01 \
        --gradient_checkpointing True \
        --bf16 True \
        --tf32 True \
        --deepspeed ${DS_CONFIG} \
        --is_concat ${IS_CONCAT} \
        --logging_steps 1 \
        --log_on_each_node False
```
```shell
bash finetune/ds_finetune.sh
```
- å¯é€šè¿‡é…ç½®hostfileï¼Œå®ç°å•æœºã€å¤šæœºè®­ç»ƒã€‚
- å¯é€šè¿‡é…ç½®ds_configï¼Œå®ç°zero2ã€zero3ã€‚
- å¯é€šè¿‡é…ç½®fp16ã€bf16å®ç°æ··åˆç²¾åº¦è®­ç»ƒï¼Œå»ºè®®ä½¿ç”¨bf16ï¼Œä¸é¢„è®­ç»ƒæ¨¡å‹ä¿æŒä¸€è‡´ã€‚
- å¯é€šè¿‡é…ç½®is_concatå‚æ•°ï¼Œæ§åˆ¶è®­ç»ƒæ•°æ®æ˜¯å¦æ‹¼æ¥ï¼Œå½“è®­ç»ƒæ•°æ®é‡çº§è¾ƒå¤§æ—¶ï¼Œå¯é€šè¿‡æ‹¼æ¥æå‡è®­ç»ƒæ•ˆç‡ã€‚

<br>

# è®¸å¯è¯

æœ¬ä»“åº“æºç éµå¾ªå¼€æºè®¸å¯è¯Apache 2.0ã€‚

360æ™ºè„‘å¼€æºæ¨¡å‹æ”¯æŒå•†ç”¨ï¼Œè‹¥éœ€å°†æœ¬æ¨¡å‹åŠè¡ç”Ÿæ¨¡å‹ç”¨äºå•†ä¸šç”¨é€”ï¼Œè¯·é€šè¿‡é‚®ç®±(g-zhinao-opensource@360.cn)è”ç³»è¿›è¡Œç”³è¯·ï¼Œ å…·ä½“è®¸å¯åè®®è¯·è§[ã€Š360æ™ºè„‘å¼€æºæ¨¡å‹è®¸å¯è¯ã€‹](./360æ™ºè„‘å¼€æºæ¨¡å‹è®¸å¯è¯.txt)ã€‚
